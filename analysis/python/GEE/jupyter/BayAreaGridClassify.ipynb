{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b2165d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################\n",
    "# STAGE 1: Image Collection Composition\n",
    "# Stage 1 creates the pre-processed input dataset (Image Collection)\n",
    "# which will serve as the basis for or GeOBIA-base classification\n",
    "\n",
    "\n",
    "# This code was adapted from learning materials provided by Iryna Dronova, PhD to \n",
    "# perform GeOBIA workflow to automate green space classification\n",
    "# in the San Francisco Bay Area\n",
    "# Author: Eric Romero -- PhD Student, ESPM, UC Berkeley\n",
    "# Input data at time of last update:\n",
    "# National Agricultural Imagery Program (NAIP)\n",
    "# Senitnel-1 SAR (VH, VV)\n",
    "# Sentinel-2 Multispectral\n",
    "# Last update: 05/16/2023\n",
    "######################################\n",
    "    \n",
    "# NOTE (Eric): Library imports and map visualization\n",
    "import ipyleaflet\n",
    "import ee\n",
    "import geemap\n",
    "\n",
    "ee.Initialize()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6078921",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOTE (Eric): Import the assets will use for our AOI and class training\n",
    "#NOTE (Eric): Asset names\n",
    "BayAreaGroupsName = 'projects/earthengine-legacy/assets/users/ericromero/eej/vectors/BayAreaBlockGroupsDissolved'\n",
    "TrainName =  'projects/earthengine-legacy/assets/users/ericromero/eej/vectors/BayAreaGreenSpaceTrainSmall'\n",
    "ValName = 'projects/earthengine-legacy/assets/users/ericromero/eej/vectors/BayAreaGreenSpaceValidateSmall'\n",
    "BayAreaGridName = 'projects/earthengine-legacy/assets/users/ericromero/eej/vectors/10kmGridSubset'\n",
    "\n",
    "#TrainName =  'projects/earthengine-legacy/assets/users/ericromero/eej/vectors/TestAOIval'\n",
    "#ValName = 'projects/earthengine-legacy/assets/users/ericromero/eej/vectors/TestAOItest'\n",
    "#BayAreaGridName = 'projects/earthengine-legacy/assets/users/ericromero/eej/vectors/TestAOI'\n",
    "\n",
    "# NOTE (Eric): Import assets as FeatureCollection objects \n",
    "BayAreaGroups = ee.FeatureCollection(BayAreaGroupsName) # NOTE (Eric): Bay Area AOI\n",
    "trainpnts = ee.FeatureCollection(TrainName) # NOTE (Eric): Training data\n",
    "valpnts = ee.FeatureCollection(ValName) # NOTE (Eric): Validation data\n",
    "BayAreaGrid = ee.FeatureCollection(BayAreaGridName)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36ff2b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOTE (Eric): Pre-define functions we will use in image formation\n",
    "# and classification\n",
    "\n",
    "# NOTE (Eric): NAIP NDVI\n",
    "def NAIPaddNDVI(image):\n",
    "    \n",
    "    ndvi = image.expression('(NIR - RED) / (NIR + RED)',{\n",
    "        'RED': image.select('R'),\n",
    "        'NIR': image.select('N')}).rename('NDVI')\n",
    "    \n",
    "    return(image.addBands(ndvi, overwrite=True))\n",
    "\n",
    "# NOTE (Eric): NAIP EVI\n",
    "def NAIPaddEVI(image):\n",
    "    evi = image.expression('2.5 * ((NIR - RED) / (NIR + 6 * RED - 7.5 * BLUE + 1))',{\n",
    "                           'NIR': image.select('N'),\n",
    "                           'RED': image.select('R'),\n",
    "                           'BLUE': image.select('B')}).rename('EVI')\n",
    "    \n",
    "    return(image.addBands(evi))\n",
    "\n",
    "# NOTE (Eric): Sentinel-2 NDVI\n",
    "def S2addNDVI(image):\n",
    "    \n",
    "    ndvi = image.expression('(NIR - RED) / (NIR + RED)',{\n",
    "        'RED': image.select('B4').divide(10000),\n",
    "        'NIR': image.select('B8').divide(10000)}).rename('NDVI').copyProperties(image,['system:time_start'])\n",
    "    \n",
    "    return(image.addBands(ndvi,overwrite=True))\n",
    "\n",
    "# NOTE (Eric): Sentinel-2 Bare Soil Index (BSI)\n",
    "def S2addBSI(image):\n",
    "    bsi = image.expression('((RED + SWIR) - (NIR + BLUE)) / ((RED + SWIR) + (NIR + BLUE))',{\n",
    "        'RED': image.select('B4').divide(10000),\n",
    "        'BLUE': image.select('B2').divide(10000),\n",
    "        'NIR': image.select('B8').divide(10000),\n",
    "        'SWIR': image.select('B11').divide(10000)}).rename('BSI').copyProperties(image,['system:time_start'])\n",
    "    \n",
    "    return(image.addBands(bsi,overwrite=True))\n",
    "\n",
    "#NOTE (Eric): Sentinel-1 pseudo-Radar vegetation Index (pRVI)\n",
    "def S1addRVI(image):\n",
    "    \n",
    "    rvi = image.expression('sqrt(VV/(VV + VH)) * ( (4*VH) / (VV/VH))' , {\n",
    "        'VH' : image.select('VH'),\n",
    "        'VV' : image.select('VV')}).rename('RVI').copyProperties(image,['system:time_start'])\n",
    "    \n",
    "    return(image.addBands(rvi,overwrite=True))\n",
    "\n",
    "def maskS2clouds(image):\n",
    "    \n",
    "    qa = image.select('QA60')\n",
    "    cloudBitMask = 1 << 10\n",
    "    cirrusBitMask = 1 << 11\n",
    "    \n",
    "    mask = qa.bitwiseAnd(cloudBitMask).eq(0).And(qa.bitwiseAnd(cirrusBitMask).eq(0))\n",
    "    \n",
    "    return(image.updateMask(mask).divide(10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "109c2a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOTE (Eric): Define function that creates statistics images from NAIP, S1, and S2 collections\n",
    "# using Feature Collection geometry\n",
    "\n",
    "def ImFromFeatCollection(FeatCollection):\n",
    "    \n",
    "    #NOTE (Eric): Define time period of interest, inBands, outBands\n",
    "    S_period_of_interest = ee.Filter.date('2014-01-01', '2023-01-01')\n",
    "    NAIP_period_of_interest = ee.Filter.date('2020-01-01', '2023-01-01')\n",
    "\n",
    "    NAIPinBands = [\"R\",\"G\",\"B\",\"N\"]\n",
    "    S2inBands = [\"B2\",\"B3\",\"B4\",\"B6\",\"B8\",\"B11\"]\n",
    "    S1inBands = [\"VH\", \"VV\"]\n",
    "\n",
    "    ExtraOutBands = [\"NAIP_NDVI_MEAN\", \"NAIP_NDVI_STD\", \"NAIP_EVI_MEAN\", \"S2_NDVI_MEAN\",\n",
    "                    \"S2_NDVI_MAX\", \"S2_NDVI_STD\", \"S2_BSI_MEAN\", \"S2_BSI_MAX\", \"S2_BSI_STD\"]#,\n",
    "                    #\"S1_RVI_MAX\", \"S1_RVI_MEAN\"]\n",
    "        \n",
    "    outBands = []\n",
    "    outBands.extend(NAIPinBands)\n",
    "    outBands.extend(S2inBands)\n",
    "    #outBands.extend(S1inBands)\n",
    "    outBands.extend(ExtraOutBands)\n",
    "\n",
    "    print(f'\\nOutput dataset bands: {outBands}')\n",
    "    print(f'\\nNAIP inbands: {NAIPinBands}')\n",
    "    \n",
    "    # NOTE (Eric): Initialize ImageCollections\n",
    "    S2_dataset = ee.ImageCollection('COPERNICUS/S2_SR').filter(S_period_of_interest).filterBounds(FeatCollection).filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE',10)).map(maskS2clouds)\n",
    "    S1_dataset = ee.ImageCollection('COPERNICUS/S1_GRD').filter(S_period_of_interest).filterBounds(FeatCollection)\n",
    "    NAIP_dataset = ee.ImageCollection('USDA/NAIP/DOQQ').filter(NAIP_period_of_interest).filterBounds(FeatCollection)\n",
    "    \n",
    "    \n",
    "    #NOTE (Eric): Filter Sentinel-1 collection for VV/VH polarizations and IW Swath mode\n",
    "    allPolIW = S1_dataset.filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VH')).filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VV')).filter(ee.Filter.eq('instrumentMode', 'IW'))\n",
    "    \n",
    "    #NOTE (Eric): Add calculated indices as bands to Collections\n",
    "    naip_collection = NAIP_dataset.select(NAIPinBands).map(NAIPaddNDVI).map(NAIPaddEVI);\n",
    "    s2_collection = S2_dataset.select(S2inBands).map(S2addNDVI).map(S2addBSI)\n",
    "    s1_collection = allPolIW.select(S1inBands).map(S1addRVI)\n",
    "    \n",
    "    #NOTE (Eric): Calculate means, medians, std devs, and maxes of bands/indices over archive of each collection\n",
    "    # Add calculated stats as individual bands to output image\n",
    "    \n",
    "    #NOTE (Eric): NAIP calculations\n",
    "    naip_median = naip_collection.select(NAIPinBands).median().clipToCollection(FeatCollection)\n",
    "    naip_ndvimean = naip_collection.select('NDVI').reduce(ee.Reducer.mean()).rename(\"NAIP_NDVI_MEAN\").clipToCollection(FeatCollection)\n",
    "    naip_ndvistd = naip_collection.select('NDVI').reduce(ee.Reducer.stdDev()).float().rename(\"NAIP_NDVI_STD\").clipToCollection(FeatCollection)\n",
    "    naip_evimean = naip_collection.select('EVI').reduce(ee.Reducer.mean()).rename(\"NAIP_EVI_MEAN\").clipToCollection(FeatCollection)\n",
    "\n",
    "    #NOTE (Eric): Sentinel-2 Calculations\n",
    "    s2_median = s2_collection.select(S2inBands).median();\n",
    "    s2_ndvimean = s2_collection.select('NDVI').reduce(ee.Reducer.mean()).rename(\"S2_NDVI_MEAN\").clipToCollection(FeatCollection)\n",
    "    s2_ndvistd = s2_collection.select('NDVI').reduce(ee.Reducer.stdDev()).float().rename(\"S2_NDVI_STD\").clipToCollection(FeatCollection)\n",
    "    s2_ndvimax = s2_collection.select('NDVI').reduce(ee.Reducer.max()).rename(\"S2_NDVI_MAX\").clipToCollection(FeatCollection)\n",
    "\n",
    "    s2_bsimean = s2_collection.select('BSI').reduce(ee.Reducer.mean()).rename(\"S2_BSI_MEAN\").clipToCollection(FeatCollection)\n",
    "    s2_bsistd = s2_collection.select('BSI').reduce(ee.Reducer.stdDev()).float().rename(\"S2_BSI_STD\").clipToCollection(FeatCollection)\n",
    "    s2_bsimax = s2_collection.select('BSI').reduce(ee.Reducer.max()).rename(\"S2_BSI_MAX\").clipToCollection(FeatCollection)\n",
    "\n",
    "    #NOTE (Eric): Sentinel-1 Calculations\n",
    "    s1_median = s1_collection.select(S1inBands).median();\n",
    "    s1_rvimean = s1_collection.select('RVI').reduce(ee.Reducer.mean()).rename(\"S1_RVI_MEAN\").clipToCollection(FeatCollection)\n",
    "    s1_rvistd = s1_collection.select('RVI').reduce(ee.Reducer.stdDev()).float().rename(\"S1_RVI_STD\").clipToCollection(FeatCollection)\n",
    "    s1_rvimax = s1_collection.select('RVI').reduce(ee.Reducer.max()).rename(\"S1_RVI_MAX\").clipToCollection(FeatCollection)\n",
    "    \n",
    "    #NOTE (Eric): Add the index statistic bands to the median bands from original imagery \n",
    "    # and clip the dataset with the ROI\n",
    "    compclip = naip_median.addBands(naip_ndvimean).addBands(naip_ndvistd).addBands(naip_evimean).addBands(s2_median).addBands(s2_ndvimean).addBands(s2_ndvistd).addBands(s2_ndvimax).addBands(s2_bsimean).addBands(s2_bsistd).addBands(s2_bsimax).addBands(s1_median).addBands(s1_rvimean).addBands(s1_rvistd).addBands(s1_rvimax).clipToCollection(FeatCollection)\n",
    "    \n",
    "    #NOTE (Eric): Select and extract the images with the desidered bands defined as outBands\n",
    "    final_bands = ee.Image(compclip.select(outBands)).toFloat(); #select only the bands specified earlier in the outBands\n",
    "    \n",
    "    return(final_bands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "613e1565",
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################\n",
    "# STAGE 2: GeOBIA Classification\n",
    "# This code was adapted from methods developed by Tassi A., Vizzari M., 2020,\n",
    "# “Object-oriented LULC classification in Google Earth Engine combining SNIC, GLCM, and Machine Learning algorithms”,\n",
    "# Remote Sens. 2020, 12(22), 3776; https://doi.org/10.3390/rs12223776.\n",
    "# This code is intended for developing object-based image classification of urban green space \n",
    "# in the greater San Francisco Bay Area\n",
    "\n",
    "\n",
    "# NOTE FROM THE AUTHORS (above doi) FOR THIS PART\n",
    "# 1)Input requirements\n",
    "# - roi: region of interest\n",
    "# - trainpnts: feature collection containing all the training data\n",
    "# - valpnts: validation points randomly generated and manually labelled used to assess the output\n",
    "# accuracy\n",
    "# - dataset: previously generated dataset using the following code:\n",
    "# \"https://code.earthengine.google.com/3b02d59f8dd400c450e380cc830247a2\"\n",
    "\n",
    "# 2) Pixel-based Approach\n",
    "# Perfoms a pixel-based classification using the bands selected between those available in the\n",
    "# dataset previosly generated\n",
    "# bands= dataset.bandNames()\n",
    "\n",
    "# 3) Object-oriented Approach\n",
    "# Perfoms an object-oriented approach using the same band selected in the previous approach\n",
    "# - The user can be set the variable \"size_segmentation\" that is the superpixel seed location spacing,\n",
    "# in pixels.\n",
    "# - Prediction bands used for the classification.\n",
    "###################################################\n",
    "# NOTE (Eric): Define a function that trains a Random Forest Classifier using SNIC GeOBIA, and\n",
    "# the user-provided training/imagery\n",
    "def TrainRF(image, trainpnts):\n",
    "    \n",
    "    \n",
    "  \n",
    "    # NOTE (Eric): Extract classification bands from input image\n",
    "    classBands = image.bandNames()\n",
    "\n",
    "    #NOTE (Eric): Select the bands from classBands var\n",
    "    dataset = image.select(classBands)\n",
    "\n",
    "    # ---- GeOBIA Training ----\n",
    "    # NOTE (Iryna): Specify the spacing of the 'superpixel' seeds for initial object creation\n",
    "    # by setting the superpixel seed location spacing, in pixels: (5 - 10 - 15 - 20)\n",
    "    size_segmentation = 10\n",
    "\n",
    "    # NOTE (Iryna): Segmentation using a SNIC approach based on the dataset previosly generated\n",
    "    seeds = ee.Algorithms.Image.Segmentation.seedGrid(size_segmentation) # to get spaced grid notes ata distance specified by segmentation size parameter\n",
    "    snic = ee.Algorithms.Image.Segmentation.SNIC(image = dataset, # our multi-band image with selected bands same as for pixel-based\n",
    "                                                compactness = 0, # allow flexibility in object shape, no need to force compactness\n",
    "                                                connectivity = 8, # use all 8 neighboring pixels in a pixel neighborhood\n",
    "                                                neighborhoodSize = 64,\n",
    "                                                seeds = seeds)\n",
    "\n",
    "    # NOTE (Iryna): The next step generates a list of band names from the snic image, but without \"clusters\"\n",
    "    # since we don't need to use pixel values of their cluster IDs as a basis for class mapping:\n",
    "    predictionBands = snic.bandNames().remove(\"clusters\")\n",
    "\n",
    "    # NOTE (Iryna): Classification using the classifier with the training bands called predictionBands\n",
    "    # get training samples from the modified image with 'object'-mean pixel values:\n",
    "    training_geobia = snic.select(predictionBands).sampleRegions(collection = trainpnts,\n",
    "                                                                properties =  ['LULC'],\n",
    "                                                                scale = 5)\n",
    "\n",
    "    # NOTE (Iryna): Specify our random forest classifier and train:\n",
    "    RF = ee.Classifier.smileRandomForest(50).train(features = training_geobia,\n",
    "                                                  classProperty = 'LULC',\n",
    "                                                  inputProperties = predictionBands)\n",
    "\n",
    "    # NOTE (Eric): apply the trained model\n",
    "    #classy_RF = snic.select(predictionBands).classify(RF,'Classified')\n",
    "    #classyBandNames = classy_RF.bandNames()\n",
    "    #class_band = classy_RF.select(['Classified']).toByte()\n",
    "\n",
    "    return(RF)\n",
    "\n",
    "#NOTE (Eric): Define a function that splits our image by grid\n",
    "def gridSplit(i):\n",
    "    \n",
    "    filt = BayAreaGrid.filter(ee.Filter.eq('ID',i))\n",
    "    grid_im = Im.clip(filt)\n",
    "    return(grid_im)\n",
    "\n",
    "#NOTE (Eric): Define a function that that classifies a feature collection using SNIC GeOBIA and pre-trained Random Forest\n",
    "def ClassifyGeOBIA(image):\n",
    "    # NOTE (Iryna): Specify the spacing of the 'superpixel' seeds for initial object creation\n",
    "    # by setting the superpixel seed location spacing, in pixels: (5 - 10 - 15 - 20)\n",
    "    size_segmentation = 10\n",
    "\n",
    "    # NOTE (Iryna): Segmentation using a SNIC approach based on the dataset previosly generated\n",
    "    seeds = ee.Algorithms.Image.Segmentation.seedGrid(size_segmentation) # to get spaced grid notes ata distance specified by segmentation size parameter\n",
    "    snic = ee.Algorithms.Image.Segmentation.SNIC(image = image, # our multi-band image with selected bands same as for pixel-based\n",
    "                                                compactness = 0, # allow flexibility in object shape, no need to force compactness\n",
    "                                                connectivity = 8, # use all 8 neighboring pixels in a pixel neighborhood\n",
    "                                                neighborhoodSize = 64,\n",
    "                                                seeds = seeds)\n",
    "    #NOTE (Eric): Extract bands used for classification\n",
    "    predictionBands=snic.bandNames().remove(\"clusters\")\n",
    "\n",
    "    #NOTE (Eric): Apply the trained Random Forest\n",
    "    snic = snic.select(predictionBands).classify(BayAreaRF)\n",
    "    snic = snic.toByte()\n",
    "    classified = ee.Image(snic.select('classification')).toByte()\n",
    "    \n",
    "    return(classified)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b981692b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Output dataset bands: ['R', 'G', 'B', 'N', 'B2', 'B3', 'B4', 'B6', 'B8', 'B11', 'NAIP_NDVI_MEAN', 'NAIP_NDVI_STD', 'NAIP_EVI_MEAN', 'S2_NDVI_MEAN', 'S2_NDVI_MAX', 'S2_NDVI_STD', 'S2_BSI_MEAN', 'S2_BSI_MAX', 'S2_BSI_STD']\n",
      "\n",
      "NAIP inbands: ['R', 'G', 'B', 'N']\n",
      "ee.ImageCollection({\n",
      "  \"functionInvocationValue\": {\n",
      "    \"functionName\": \"Collection.filter\",\n",
      "    \"arguments\": {\n",
      "      \"collection\": {\n",
      "        \"functionInvocationValue\": {\n",
      "          \"functionName\": \"Collection.filter\",\n",
      "          \"arguments\": {\n",
      "            \"collection\": {\n",
      "              \"functionInvocationValue\": {\n",
      "                \"functionName\": \"ImageCollection.load\",\n",
      "                \"arguments\": {\n",
      "                  \"id\": {\n",
      "                    \"constantValue\": \"USDA/NAIP/DOQQ\"\n",
      "                  }\n",
      "                }\n",
      "              }\n",
      "            },\n",
      "            \"filter\": {\n",
      "              \"functionInvocationValue\": {\n",
      "                \"functionName\": \"Filter.dateRangeContains\",\n",
      "                \"arguments\": {\n",
      "                  \"leftValue\": {\n",
      "                    \"functionInvocationValue\": {\n",
      "                      \"functionName\": \"DateRange\",\n",
      "                      \"arguments\": {\n",
      "                        \"end\": {\n",
      "                          \"constantValue\": \"2023-01-01\"\n",
      "                        },\n",
      "                        \"start\": {\n",
      "                          \"constantValue\": \"2020-01-01\"\n",
      "                        }\n",
      "                      }\n",
      "                    }\n",
      "                  },\n",
      "                  \"rightField\": {\n",
      "                    \"constantValue\": \"system:time_start\"\n",
      "                  }\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      },\n",
      "      \"filter\": {\n",
      "        \"functionInvocationValue\": {\n",
      "          \"functionName\": \"Filter.intersects\",\n",
      "          \"arguments\": {\n",
      "            \"leftField\": {\n",
      "              \"constantValue\": \".all\"\n",
      "            },\n",
      "            \"rightValue\": {\n",
      "              \"functionInvocationValue\": {\n",
      "                \"functionName\": \"Feature\",\n",
      "                \"arguments\": {\n",
      "                  \"geometry\": {\n",
      "                    \"functionInvocationValue\": {\n",
      "                      \"functionName\": \"Collection.geometry\",\n",
      "                      \"arguments\": {\n",
      "                        \"collection\": {\n",
      "                          \"functionInvocationValue\": {\n",
      "                            \"functionName\": \"Collection.loadTable\",\n",
      "                            \"arguments\": {\n",
      "                              \"tableId\": {\n",
      "                                \"constantValue\": \"projects/earthengine-legacy/assets/users/ericromero/eej/vectors/10kmGridSubset\"\n",
      "                              }\n",
      "                            }\n",
      "                          }\n",
      "                        }\n",
      "                      }\n",
      "                    }\n",
      "                  }\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# NOTE (Eric): Create image to use for training w/ composited stats\n",
    "Im = ImFromFeatCollection(BayAreaGrid)\n",
    "\n",
    "#NOTE (Eric): Train RF model\n",
    "BayAreaRF = TrainRF(Im, trainpnts)\n",
    "\n",
    "#NOTE (Eric): Create sequence object to form collection over\n",
    "seq = ee.List.sequence(0,384)\n",
    "\n",
    "#NOTE (Eric): Use sequence function to form image collection of original input dataset but clipped over\n",
    "# series of smaller regions\n",
    "ImCollection = ee.ImageCollection.fromImages(seq.map(gridSplit))\n",
    "\n",
    "#NOTE (Eric): Iterate over the image collection, classify each image, \n",
    "# and write its classification to drive\n",
    "ImCollectionList = ImCollection.toList(385)\n",
    "\n",
    "out_fn_ext = '{}_EEJClassificationR2'\n",
    "\n",
    "for i in range(385):\n",
    "    \n",
    "    #NOTE (Eric): Format export fn with feature ID\n",
    "    export_fn = out_fn_ext.format(i)\n",
    "    \n",
    "    #NOTE (Eric): Get feature, geometry, and image from lists\n",
    "    gridCollection = ee.FeatureCollection(BayAreaGrid.filter(ee.Filter.eq('ID',i)))\n",
    "    gridList = ee.List(gridCollection.toList(1))\n",
    "    grid = ee.Feature(gridList.get(0))\n",
    "    grid_geom = ee.Geometry(grid.geometry())\n",
    "    im = ee.Image(ImCollectionList.get(i))\n",
    "    \n",
    "    classy = ee.Image(ClassifyGeOBIA(im)).select('classification').toByte().clip(grid_geom)\n",
    "    \n",
    "    task = ee.batch.Export.image.toDrive(image=classy,\n",
    "                                         description=export_fn,\n",
    "                                         folder='EEJClassificationR2',\n",
    "                                         region = grid_geom,\n",
    "                                         scale=5,\n",
    "                                         skipEmptyTiles=True,\n",
    "                                         shardSize=64,\n",
    "                                         maxPixels=1e13)\n",
    "    task.start()\n",
    "\n",
    "#NOTE (Eric): Input image visualization\n",
    "#Map = geemap.Map(center=[37.7739,-122.4312],zoom=10)\n",
    "#Map.addLayer(Im, {'bands': ['R','G','B'], 'min':[0,0,0], 'max': [255,255,255]})\n",
    "#Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d6c0f5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Output dataset bands: ['R', 'G', 'B', 'N', 'B2', 'B3', 'B4', 'B6', 'B8', 'B11', 'NAIP_NDVI_MEAN', 'NAIP_NDVI_STD', 'NAIP_EVI_MEAN', 'S2_NDVI_MEAN', 'S2_NDVI_MAX', 'S2_NDVI_STD', 'S2_BSI_MEAN', 'S2_BSI_MAX', 'S2_BSI_STD']\n",
      "\n",
      "NAIP inbands: ['R', 'G', 'B', 'N']\n"
     ]
    }
   ],
   "source": [
    "#NOTE (Eric): RUN THIS AND REPLACE MISSING INDEX LIST WITH TILES WHOSE COMPUTATION TIMED OUT\n",
    "# ONLY RUN IF MISSING TILES FROM ABOVE EXPORT\n",
    "missing_indices = [128]\n",
    "\n",
    "# NOTE (Eric): Create image to use for training w/ composited stats\n",
    "Im = ImFromFeatCollection(BayAreaGrid)\n",
    "\n",
    "#NOTE (Eric): Train RF model\n",
    "BayAreaRF = TrainRF(Im, trainpnts)\n",
    "\n",
    "#NOTE (Eric): Create sequence object to form collection over\n",
    "seq = ee.List.sequence(0,384)\n",
    "\n",
    "#NOTE (Eric): Use sequence function to form image collection of original input dataset but clipped over\n",
    "# series of smaller regions\n",
    "ImCollection = ee.ImageCollection.fromImages(seq.map(gridSplit))\n",
    "\n",
    "#NOTE (Eric): Iterate over the image collection, classify each image, \n",
    "# and write its classification to drive\n",
    "ImCollectionList = ImCollection.toList(385)\n",
    "\n",
    "out_fn_ext = '{}_EEJClassificationR2'\n",
    "\n",
    "for i in missing_indices:\n",
    "    \n",
    "    #NOTE (Eric): Format export fn with feature ID\n",
    "    export_fn = out_fn_ext.format(i)\n",
    "    \n",
    "    #NOTE (Eric): Get feature, geometry, and image from lists\n",
    "    gridCollection = ee.FeatureCollection(BayAreaGrid.filter(ee.Filter.eq('ID',i)))\n",
    "    gridList = ee.List(gridCollection.toList(1))\n",
    "    grid = ee.Feature(gridList.get(0))\n",
    "    grid_geom = ee.Geometry(grid.geometry())\n",
    "    im = ee.Image(ImCollectionList.get(i))\n",
    "    \n",
    "    classy = ee.Image(ClassifyGeOBIA(im)).select('classification').toByte().clip(grid_geom)\n",
    "    \n",
    "    task = ee.batch.Export.image.toDrive(image=classy,\n",
    "                                         description=export_fn,\n",
    "                                         folder='EEJClassificationR2',\n",
    "                                         region = grid_geom,\n",
    "                                         scale=5,\n",
    "                                         skipEmptyTiles=True,\n",
    "                                         shardSize=64,\n",
    "                                         maxPixels=1e13)\n",
    "    task.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea1b365",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gmap",
   "language": "python",
   "name": "gmap"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
